# Historique des Publications


## 03 / 06 / 2025
TODO

## 27 / 05 / 2025

ğŸ’¡ ğ‚ğ¨ğ¦ğ¦ğğ§ğ­ ğğ¢ğ¦ğğ§ğ¬ğ¢ğ¨ğ§ğ§ğğ«, ğ¨ğ©ğ­ğ¢ğ¦ğ¢ğ¬ğğ« ğğ­ ğ›ğğ§ğœğ¡ğ¦ğšğ«ğ¤ğğ« ğ¥ğğ¬ ğ¢ğ§ğŸğ«ğšğ¬ğ­ğ«ğ®ğœğ­ğ®ğ«ğğ¬ ğªğ®ğ¢ ğ¬ğğ«ğ¯ğğ§ğ­ ğ¯ğ¨ğ¬ ğ‹ğ‹ğŒ ?

La plupart des benchmarks utilisÃ©s jusquâ€™ici pour Ã©valuer le serving des LLM reposent sur des charges de travail artificielles, trÃ¨s Ã©loignÃ©es de la rÃ©alitÃ©. Pourtant, pour bien dimensionner et optimiser les infrastructures (GPU, cloud, orchestrationâ€¦), ğ’Šğ’ ğ’†ğ’”ğ’• ğ’„ğ’“ğ’–ğ’„ğ’Šğ’‚ğ’ ğ’…ğ’† ğ’„ğ’ğ’ğ’‘ğ’“ğ’†ğ’ğ’…ğ’“ğ’† ğ’ğ’†ğ’” ğ’–ğ’”ğ’‚ğ’ˆğ’†ğ’” ğ’“ğ’†Ìğ’†ğ’ğ’” : pics de charge, diversitÃ© des requÃªtes, comportements clientsâ€¦

ğŸ” ğ‘³ğ’† ğ’‘ğ’‚ğ’‘ğ’Šğ’†ğ’“ ğ‘ºğ’†ğ’“ğ’—ğ’†ğ‘®ğ’†ğ’ (ğ’‚ğ’“ğ‘¿ğ’Šğ’—:2505.09999) ğ’‚ğ’‘ğ’‘ğ’ğ’“ğ’•ğ’† ğ’…ğ’†ğ’” ğ’“ğ’†Ìğ’‘ğ’ğ’ğ’”ğ’†ğ’” ğ’„ğ’ğ’ğ’„ğ’“ğ’†Ì€ğ’•ğ’†ğ’”.
Les auteurs ont analysÃ© plusieurs milliards de requÃªtes issues de vÃ©ritables applications en production, couvrant des modÃ¨les variÃ©s (texte, multimodal, reasoning). Leur objectif : proposer des workloads rÃ©alistes pour mieux Ã©valuer les performances des LLMs et guider le design des infrastructures.

ğ‘ªğ’† ğ’’ğ’–â€™ğ’Šğ’ğ’” ğ’ğ’ƒğ’”ğ’†ğ’“ğ’—ğ’†ğ’ğ’• :
ğŸ“Š ğ•ğšğ«ğ¢ğšğ›ğ¢ğ¥ğ¢ğ­ğÌ ğğ±ğ­ğ«ğÌ‚ğ¦ğ ğğğ¬ ğ°ğ¨ğ«ğ¤ğ¥ğ¨ğšğğ¬ ğ¦ğ®ğ¥ğ­ğ¢ğ¦ğ¨ğğšğ®ğ±
Les requÃªtes impliquant texte, image, audio ou vidÃ©o sont trÃ¨s hÃ©tÃ©rogÃ¨nes en longueur et en coÃ»t. La phase de prÃ©traitement (ex : encoder une image) peut devenir un vrai goulet dâ€™Ã©tranglement.

âš¡ ğğ¢ğœğ¬ ğğ ğœğ¡ğšğ«ğ ğ ğ¬ğ¨ğ®ğğšğ¢ğ§ğ¬ (ğ›ğ®ğ«ğ¬ğ­ğ¢ğ§ğğ¬ğ¬)
Les arrivÃ©es de requÃªtes ne sont pas rÃ©guliÃ¨res, mais marquÃ©es par des pics imprÃ©visibles, souvent liÃ©s Ã  quelques gros clients ou Ã  des Ã©vÃ¨nements ponctuels.

ğŸ§  ğ‡ğÌğ­ğÌğ«ğ¨ğ ğÌğ§ğÌğ¢ğ­ğÌ ğğğ¬ ğ®ğ¬ğšğ ğğ¬ ğ«ğğšğ¬ğ¨ğ§ğ¢ğ§ğ 
Les conversations complexes (avec plusieurs Ã©changes successifs) prÃ©sentent des profils trÃ¨s variÃ©s : certaines sont trÃ¨s courtes, dâ€™autres beaucoup plus longues, ce qui impose des exigences particuliÃ¨res en gestion de mÃ©moire et de contexte pour les serveurs LLM.

ğğ¨ğ®ğ«ğªğ®ğ¨ğ¢ ğœâ€™ğğ¬ğ­ ğ¢ğ¦ğ©ğ¨ğ«ğ­ğšğ§ğ­ ?
Les benchmarks traditionnels sous-estiment la complexitÃ© rÃ©elle du serving LLM. Utiliser des workloads rÃ©alistes, comme ceux proposÃ©s par ServeGen, permet dâ€™anticiper les besoins dâ€™infrastructure, dâ€™identifier les vrais goulets dâ€™Ã©tranglement, et de tester les optimisations dans des conditions proches de la production.
ğŸ’¬ ğ‘„ğ‘¢ğ‘’ğ‘™ ğ‘ ğ‘¢ğ‘—ğ‘’ğ‘¡ ğ¼ğ´ ğ‘œğ‘¢ ğ¿ğ¿ğ‘€ ğ‘ğ‘–ğ‘šğ‘’ğ‘Ÿğ‘–ğ‘’ğ‘§-ğ‘£ğ‘œğ‘¢ğ‘  ğ‘ğ‘¢ğ‘’ ğ‘—ğ‘’ ğ‘‘ğ‘’Ìğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ‘’ ğ‘™ğ‘ ğ‘ ğ‘’ğ‘šğ‘ğ‘–ğ‘›ğ‘’ ğ‘ğ‘Ÿğ‘œğ‘â„ğ‘ğ‘–ğ‘›ğ‘’ ? ğ·ğ‘–ğ‘¡ğ‘’ğ‘ -ğ‘šğ‘œğ‘– ğ‘’ğ‘› ğ‘ğ‘œğ‘šğ‘šğ‘’ğ‘›ğ‘¡ğ‘ğ‘–ğ‘Ÿğ‘’ !
ğ‘‰ğ‘œğ‘  ğ‘–ğ‘‘ğ‘’Ìğ‘’ğ‘  ğ‘šâ€™ğ‘ğ‘–ğ‘‘ğ‘’ğ‘Ÿğ‘œğ‘›ğ‘¡ ğ‘Ì€ ğ‘â„ğ‘œğ‘–ğ‘ ğ‘–ğ‘Ÿ ğŸ‘€â€‹

Le papier - ServeGen: Workload Characterization and Generation of Large Language Model Serving in Production


## 20 / 05 / 2025
ğ—Ÿğ—® ğ—°ğ—¼ğ—»ğ—°ğ—²ğ—½ğ˜ğ—¶ğ—¼ğ—» ğ—±â€™ğ˜‚ğ—» ğ˜€ğ˜†ğ˜€ğ˜ğ—²Ì€ğ—ºğ—² ğ—±â€™ğ—œğ—” ğ—½ğ—¼ğ˜€ğ—² ğ˜ğ—¼ğ˜‚ğ—·ğ—¼ğ˜‚ğ—¿ğ˜€ ğ—¹ğ—® ğ—¾ğ˜‚ğ—²ğ˜€ğ˜ğ—¶ğ—¼ğ—» ğ—±ğ˜‚ ğ—°ğ—µğ—¼ğ—¶ğ˜… ğ—±ğ˜‚ ğ—ºğ—¼ğ—±ğ—²Ì€ğ—¹ğ—²â€¯: ğ—¾ğ˜‚ğ—²ğ—¹ğ—¹ğ—² ğ—®ğ—¿ğ—°ğ—µğ—¶ğ˜ğ—²ğ—°ğ˜ğ˜‚ğ—¿ğ—² ğŸ—ï¸, ğ—¾ğ˜‚ğ—²ğ—¹ğ—¹ğ—² ğ˜ğ—®ğ—¶ğ—¹ğ—¹ğ—² ğŸ“â€¯?

MÃªme avec une bonne stratÃ©gie de tests, le premier choix reste souvent incertain.

Le papier "WorldPM: Scaling Human Preference Modeling" (ğŸ‘‡ lien en commentaireğŸ‘‡) publiÃ© par les Ã©quipes de Qwen apporte des Ã©lÃ©ments concrets pour Ã©clairer cette phase.
Les auteurs analysent comment la taille du modÃ¨le et le volume de donnÃ©es d'entraÃ®nement influencent la capacitÃ© des IA Ã  modÃ©liser les prÃ©fÃ©rences humaines.

ğ—˜ğ˜ ğ˜€ğ˜‚ğ—¿ğ˜ğ—¼ğ˜‚ğ˜, ğ—¶ğ—¹ğ˜€ ğ—ºğ—¼ğ—»ğ˜ğ—¿ğ—²ğ—»ğ˜ ğ—¾ğ˜‚ğ—² ğ—°ğ—²ğ˜ ğ—¶ğ—ºğ—½ğ—®ğ—°ğ˜ ğ—±ğ—²Ìğ—½ğ—²ğ—»ğ—± ğ—³ğ—¼ğ—¿ğ˜ğ—²ğ—ºğ—²ğ—»ğ˜ ğ—±ğ˜‚ ğ˜ğ˜†ğ—½ğ—² ğ—±ğ—² ğ˜ğ—®Ì‚ğ—°ğ—µğ—²ğ˜€ ğ˜ƒğ—¶ğ˜€ğ—²Ìğ—²ğ˜€â€¯!

Ce genre dâ€™Ã©tude est prÃ©cieuseâ€¯: en ayant bien dÃ©fini ses cas dâ€™usage, il devient plus facile de faire des choix techniques adaptÃ©s ğŸ¯

ğ‘ğµ : ğ¼ğ‘™ ğ‘“ğ‘ğ‘¢ğ‘¡ ğ‘ğ‘–ğ‘’ğ‘› ğ‘’ğ‘›ğ‘¡ğ‘’ğ‘›ğ‘‘ğ‘¢ ğ‘¡ğ‘œğ‘¢ğ‘—ğ‘œğ‘¢ğ‘Ÿğ‘  ğ‘¡ğ‘’ğ‘›ğ‘–ğ‘Ÿ ğ‘ğ‘œğ‘šğ‘ğ‘¡ğ‘’ ğ‘Ì€ ğ‘™ğ‘ ğ‘“ğ‘œğ‘–ğ‘  ğ‘‘ğ‘’ğ‘  ğ‘ğ‘’ğ‘Ÿğ‘“ğ‘œğ‘Ÿğ‘šğ‘ğ‘›ğ‘ğ‘’ğ‘  ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘‘ğ‘¢ğ‘’ğ‘  ğ‘’ğ‘¡ ğ‘‘ğ‘’ğ‘  ğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘  ğ‘‘â€™ğ‘–ğ‘›ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ âš–ï¸.

Le papier  - WorldPM: Scaling Human Preference Modeling
